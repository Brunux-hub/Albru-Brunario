# ğŸ¤– Asistente de CÃ³digo IA Local - CRM Albru

Asistente de cÃ³digo con IA local usando modelos open source de alta calidad, especÃ­ficamente entrenados para desarrollo de software.

## ğŸ¯ CaracterÃ­sticas

- âœ… **100% Local y Privado**: No envÃ­a tu cÃ³digo a internet
- ğŸš€ **Alta PrecisiÃ³n**: Usa modelos especializados en cÃ³digo (Qwen2.5-Coder o DeepSeek-Coder-V2)
- ğŸ§  **Contexto del Proyecto**: Entiende la estructura de tu CRM (React, Node.js, MySQL)
- ğŸ“ **Modifica CÃ³digo**: Puede leer, analizar y sugerir cambios precisos
- ğŸ’» **Ejecuta Comandos**: Git, Docker, npm, etc.
- ğŸ” **BÃºsqueda de CÃ³digo**: Encuentra patrones en tu proyecto

## ğŸ“‹ Requisitos

### Hardware MÃ­nimo:
- **CPU**: 4 cores
- **RAM**: 
  - 32GB para qwen2.5-coder:32b (mejor calidad)
  - 16GB para qwen2.5-coder:14b (balance)
  - 12GB para qwen2.5-coder:7b (mÃ­nimo)
- **Disco**: 20-40GB libres (para el modelo)
- **GPU**: Opcional pero recomendado (acelera 10-20x)

### Software:
- Python 3.9 o superior
- [Ollama](https://ollama.ai) (gestor de modelos IA)

## ğŸš€ InstalaciÃ³n

### 1. Instalar Ollama

**Windows:**
```powershell
# Descargar de https://ollama.ai y ejecutar el instalador
# O con winget:
winget install Ollama.Ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Mac:**
```bash
brew install ollama
```

### 2. Instalar Dependencias Python

```bash
cd ai-assistant
pip install -r requirements.txt
```

### 3. Descargar Modelo de IA

Elige segÃºn tu hardware:

```bash
# Mejor calidad (32GB RAM necesarios)
python assistant.py install-model qwen2.5-coder:32b

# Balance calidad/recursos (16GB RAM)
python assistant.py install-model qwen2.5-coder:14b

# MÃ­nimo (12GB RAM)
python assistant.py install-model qwen2.5-coder:7b

# Alternativa: DeepSeek Coder V2
python assistant.py install-model deepseek-coder-v2:16b
```

## ğŸ’¡ Uso

### Modo Interactivo (Recomendado)

```bash
cd ai-assistant
python assistant.py chat
```

Comandos disponibles en el chat:
- `/read <archivo>` - Leer un archivo del proyecto
- `/search <texto>` - Buscar en el cÃ³digo
- `/exec <comando>` - Ejecutar comando (git, docker, npm)
- `/clear` - Limpiar historial de conversaciÃ³n
- `/exit` - Salir

### Pregunta Ãšnica

```bash
python assistant.py ask "Â¿CÃ³mo puedo agregar validaciÃ³n de email en el formulario de registro?"
```

## ğŸ“ Ejemplos de Uso

### Ejemplo 1: AnÃ¡lisis de CÃ³digo
```
TÃº: Â¿CÃ³mo funciona el sistema de autenticaciÃ³n?
Asistente: El sistema usa JWT. AnalicÃ© backend/middleware/auth.js...
```

### Ejemplo 2: Modificar Funcionalidad
```
TÃº: Necesito agregar un filtro por fecha en la tabla de clientes
Asistente: Puedo ayudarte. NecesitarÃ¡s modificar:
1. Frontend: src/components/gtr/GtrClientsTable.tsx
2. Backend: backend/controllers/clientesController.js
...
```

### Ejemplo 3: Debug
```
TÃº: /read src/components/asesor/GestionarClienteDialog.tsx
[Muestra el cÃ³digo]
TÃº: Este componente tiene un error de tipo en lÃ­nea 1919
Asistente: Veo el problema. cliente.id puede ser undefined...
```

### Ejemplo 4: Crear Funcionalidad Nueva
```
TÃº: Quiero agregar un sistema de notificaciones push cuando un GTR asigna un cliente
Asistente: Para implementar esto necesitamos:
1. Backend: Socket.io event 'cliente_asignado'
2. Frontend: Hook useNotifications + componente NotificationBell
3. Base datos: tabla 'notificaciones'
...
```

## ğŸ¯ Modelos Recomendados

### Qwen2.5-Coder-32B â­â­â­â­â­
- **Calidad**: Excelente (casi igual a Claude)
- **RAM**: 32GB
- **Velocidad**: Media
- **Uso**: Proyectos profesionales

### Qwen2.5-Coder-14B â­â­â­â­
- **Calidad**: Muy buena
- **RAM**: 16GB
- **Velocidad**: RÃ¡pida
- **Uso**: Desarrollo diario

### DeepSeek-Coder-V2-16B â­â­â­â­
- **Calidad**: Muy buena
- **RAM**: 12GB
- **Velocidad**: RÃ¡pida
- **Uso**: Alternativa a Qwen

### Qwen2.5-Coder-7B â­â­â­
- **Calidad**: Buena
- **RAM**: 8GB
- **Velocidad**: Muy rÃ¡pida
- **Uso**: MÃ¡quinas con recursos limitados

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Usar GPU (Mucho mÃ¡s rÃ¡pido)

El asistente detectarÃ¡ automÃ¡ticamente tu GPU NVIDIA si tienes CUDA instalado.

```bash
# Verificar que Ollama usa GPU
ollama run qwen2.5-coder:32b "test" --verbose
```

### Ajustar ParÃ¡metros del Modelo

Edita `assistant.py` en la funciÃ³n `chat()`:

```python
options={
    "temperature": 0.7,    # Creatividad (0-1, menor = mÃ¡s preciso)
    "top_p": 0.9,         # Diversidad de respuestas
    "num_ctx": 8192,      # Tokens de contexto
}
```

## ğŸ“Š ComparaciÃ³n de Calidad

| Modelo | Calidad CÃ³digo | Velocidad | RAM | Costo |
|--------|---------------|-----------|-----|-------|
| Claude Sonnet 4 | â­â­â­â­â­ | RÃ¡pida | N/A | $3-15/mes |
| Qwen2.5-Coder 32B | â­â­â­â­ | Media | 32GB | Gratis |
| DeepSeek-Coder-V2 | â­â­â­â­ | RÃ¡pida | 12GB | Gratis |
| Qwen2.5-Coder 14B | â­â­â­Â½ | RÃ¡pida | 16GB | Gratis |

## ğŸ› SoluciÃ³n de Problemas

### "Ollama no responde"
```bash
# Windows
ollama serve

# Linux/Mac
systemctl start ollama
```

### "Modelo no encontrado"
```bash
ollama list  # Ver modelos instalados
python assistant.py install-model qwen2.5-coder:32b
```

### "Muy lento"
- Usa un modelo mÃ¡s pequeÃ±o (7B o 14B)
- Activa GPU si tienes NVIDIA
- Cierra otras aplicaciones

### "Se queda sin memoria"
- Usa un modelo mÃ¡s pequeÃ±o
- Reduce `num_ctx` en el cÃ³digo
- Cierra otras aplicaciones

## ğŸ“ Tutoriales

### Tutorial 1: AnÃ¡lisis de Componente
```bash
python assistant.py chat

> /read src/components/gtr/GtrClientsTable.tsx
> Explica cÃ³mo funciona este componente y sugiere mejoras de rendimiento
```

### Tutorial 2: Crear Feature Completo
```bash
> Necesito agregar un sistema de favoritos donde el asesor pueda marcar clientes
> El asesor debe poder filtrar solo sus favoritos
> Implementa backend y frontend completo
```

### Tutorial 3: Debug de Error
```bash
> /search "TypeError: Cannot read"
> Tengo este error en producciÃ³n, ayÃºdame a debuggearlo
```

## ğŸ“š Recursos

- [DocumentaciÃ³n Ollama](https://github.com/ollama/ollama)
- [Qwen2.5-Coder Paper](https://arxiv.org/abs/2409.12186)
- [DeepSeek-Coder](https://github.com/deepseek-ai/DeepSeek-Coder)

## ğŸ¤ Contribuir

Si encuentras bugs o tienes sugerencias, crea un issue o pull request.

## ğŸ“„ Licencia

MIT License - Uso libre para proyectos comerciales y personales.

---

**Nota**: Este asistente es especÃ­fico para el CRM Albru. El modelo aprende de tu cÃ³digo y estructura, proporcionando respuestas contextualizadas a tu proyecto.
